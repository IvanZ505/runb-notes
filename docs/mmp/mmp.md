# Minds Machines & Persons

## Grading
- Attendance: 5%
- Reading Response: 5%
- Presentation: 20%
	- Has a slides and a handout component.
- Abstract: 5%
	- 200 word abstract for their seminar paper.
- Outline: 15%
	- A 1-page outline for the paper.
- Paper: 50%
	- About 8-pages, typed, double-spaced, 12pt font, 1" margins.


### Schemas

- We all have four domains of schemas: cognitive, perceptual, behavioral, emotional
- Tools such as concepts that we share.

> If someone is in a near vegetative state, with their capacity to express physical evidence of emotional schemas suspended, would you still consider them to be emotionally capable? How are they then set apart from machines if the only thing keeping them alive is a machine?

- Each schema in these domains is constituted by:
	- Patterns of prediction and expectation
	- Capacities
	- Representational States
### Capacities in AI
- Different AIs have different capacities for functions.
	- Some may be coded in, and others may be due to hardware.
		- e.g. We're born with the capacity to speak a language, but it is due to our species having evolved to speak a language so it became genetically encoded.
		- 2 e.g. dark light distinction, and the capacity to distinguish colors, which gets activated earlier. 
	- **Innate vs encoded**

### Representative States in AI Systems
- Deep neural networks learn hierarchical feature representations.
- Weights and biases vs layers vs statistical irregularities.

- Emotional states, beliefs, perceptions.

> Humans have different mental states, but it would be wrong to say AI does too, but they have things that are analogous.

Things part of the human mind/equivalent but doesnt fit into the 3 categories?

Examples of an artificial equivalent of representational states?

