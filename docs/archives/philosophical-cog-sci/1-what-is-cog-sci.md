# [Unit 1: What is Cognitive Science](philosophical-cog-sci.md)

## Chomsky vs Skinner

> "...perhaps the most devastating book review ever written." - Peter Godfrey-Smith

- Behaviorism vs. cognitivism
- Set the stage for cognitive science and linguistics to focus on internal, mental phenomena and meaning/reference.
	- Table, the item is the stimulus, but the behavioral is interpreting it to be a table.

### Classical Conditioning

- Pavlov was not really a behaviorist, but was interested in a more open-minded and scientific way.
- Pavlov rang a bell before feeding dogs.
- Even if there was no food, when the bell was rang, the dogs were salivating.
- It seems that there is some *association* with the sound of the bell and the food.
- **Unconditioned Stimulus** - Food
	- There is no need to be trained on the stimulus.
- **Unconditioned response** - Salivating
	- The dogs need not be trained to salivate to the food stimuli
- **Conditioned stimulus** (CS)- Bell
	- By ringing the bell, the dogs are *conditioned* to recognize this stimuli.

> This is what is called *classical conditioning* = pairing response to CS.

### Association
- Conditioning works by *co-presenting two stimuli*
- Response to the unconditioned stimuli "rubs off" onto the CS.
- It is supposed to be "simple" - no need to posit rational thought, just brute association.
	- Brute connection between food and salivation. It just *happens*. Then, by associating the bell with food, you conditioned that *bell* with the salivatory response.

#### Strength of Association
- Test the strength of the association by seeing how long + intense the response is during *extinction*.
- *Extinction* = Presentation of CS without the US (e.g. bell without food)
	- Should take a LOT of trials of extinction if you go through thousands of trials of association.
- *Could this extend to humans???*

## Behaviorism
- *Watson (1920)* - "Little Albert" experiments.
- 12 m/o was scared by loud noises.
- When loud noises were present, there would also be furry animals.
- Albert was then associating fear with furry animals.

### Operant Conditioning
- Increase/decrease stimulus-response pairing through *reinforcement* + *punishment*.
- Positive reinforcement (+ good)
- Negative reinforcement (- bad)
	- You take away something bad. (If you are shocking the rat, once they press the lever, the shocking stops.)
- Positive punishment (+ bad)
- Negative punishment (- good)

### Classical Associationism
- Problem: What is associated with what, exactly? 
- Classical associationism: A representation ("idea") of the bell is associated w representation of food.
- But could we get rid of the "ideas"

---

### Behaviorism Cont.
- Talk of the mind, representations, etc., is unscientific
- We can just talk about the paired *stimulus* and *response*.
	- "Stimulus" = thing out there in the world.
	- "Response" = observable behavior. (Smiling when seeing your friend.)
		- Feeling happy when seeing friend **is not** a response.
- ***All behavior is conditioned***

1. In Behaviorism, there is *no appeal* to mental states -- only stimulus-response pairings.
2. No appeal to anything innate beyond. (Everything is learned to Behaviorists except things inborn/innate.)
	1. "Instincts" (US-response pairings)
	2. "Drives" (Hunger... etc)

##### Why would you want to explain all behavior with such simple tools?

- Empirical motivation: Move beyond "[introspective](../../archives/cog-decision/cognitive-architecture.md#Introspection)" psychology.
	- Behaviorism was an EXTREME move in the opposite direction to say, "nuh uh, nothing wit the mind"
- Philosophical motivation: Exorcise the "ghost in the machine" (Ryle, Quine)
	- Around the time Chomsky, there was also a lot of philosophy.

##### Language
- What is a scientifically respectable counterexample?
	- "Feelings don't count"
- Language: Rich, sophisticated, unpredictable, distinctively human, and *expresses thought*
	- Professor is conveying so much information through just talking.
	- Can it really be all attributed to conditioning and Behaviorism???
		- Most remote from Behaviorism.
- Skinner knew that, so he wrote *Verbal Behavior* (1957) - Radical extension of Behaviorism to complex human behavior.

## Skinner Box

- Stimulus: Light flash
- Response: Bar press
- Reinforcer: Food
- Punishment: Shock

> These are all relatively well-defined in these experiments.

#### Chomsky's Critique

- *Dilemma* - Two horns:

1. These terms are used with their technical meanings and the theory is *obviously false*
2. They are vague and empty, and *secretly smuggle in mental states*

##### First Horn: Stimulus
- Must be a lawful relation between Stimulus (S) and Response (R)
	- The S "controls" the R.
- When you look at a painting and say "Dutch" - What's the S? The painting?
	- Same S when you say "Vermeer" or "Clashes with the wallpaper", or "I thought you liked abstract art"
	- There is no reason to assume that each time the stimulus is presented, they will give the same response.
- **No lawful pairing.** - Obviously false

> Skinner argues that you are NOT thinking of the stimulus in the right way.

- There are subtle properties of the painting that causes a different stimuli, so each time, it is NOT the same stimuli.

> "*Stimuli are no longer part of the outside physical world; they are driven back into the organism. We identify the stimuli when we hear the response. It is clear from such examples, which abound, that the talk of 'stimulus control' simply disguised a complete retreat to mentalistic psychology.*" - Chomsky

- Horn 2: Vacuous, smuggles in mental notions (What you're attending to, thinking about)

#### Proper Nouns

##### Skinner
- Verbal responses that are "under the control of a stimulus"
- Is a little weird, as you can use names for people you've never encountered directly, like Chomsky. 
	- You can still refer to them as Chomsky even though you do not have that stimulus.
- By this definition, the *response* to seeing that stimulus again and again should be the same!
	- You are constantly "stimulated by" yourself, and yet not constantly saying your own name (no S "control")

> "It appears that the word 'control' here is merely a misleading paraphrase for the traditional 'denote' or 'refer'" - Chomsky

- *Horn 1* or *Horn 2* again.

### Response Strength
- In the Skinner box, this is measured by rate of bar presses during extinction.

*What about in verbal behavior?*

- Volume, pitch, speed, amount + rate of repetition, low delay, size (in writing), & overall frequency or "probability"
- **Skinner:** "if we are shown a prized work of art and exclaim 'Beautiful!', the speed and energy of the response will not be lost on the owner."

##### Chomsky's Response

> "It does not appear totally obvious that in this case the way to impress the owner is to shriek in a loud, high-pitched voice, repeatedly, and with no delay (high response strength). It may be equally effective to look at the picture silently (long delay) and then murmur in a soft, low pitched voice. (By def, very low response strength.)"

- Skinner's measurements of verbal behavior response strength is bogus.

#### Reinforcer
- Why do we expend effort doing novel, creative behavior (music, writing, even talking to yourself)?
	- Validation? 
- Skinner: "*Verbal behavior* may reach over centuries or to thousands of listeners or readers at the same time. The writer may not be reinforced often or immediately, but his net reinforcement may be great."
	- This is contradictory, as in a Behaviorist model, the "thought" of the reinforcement should **not** be in the theory.

##### Chomsky's Response to Reinforcer
- Future readers aren't reinforcing S, because they are not a S at all!
- The phrase "X is reinforced by Y" (stimulus, state of affairs, events, etc...) is a *cover term* for "X wants Y, X likes Y, X wishes that Y were the case", etc...
	- "Reinforcement" here does not have any explanatory force.
	- Calls Skinner delusional for trying to use "this paraphrase to introduce any new clarity or objectivity into the description of wishing, liking, etc..."

#### Two Deeper Problems

*With Skinner's proposal as well as Behaviorism in general*

##### Syntax of a sentence is not observable
- John is easy to please... vs John is eager to please...
	- In the ordering of the sentence, everything is laid out the same.
- **Paraphrase:** It's easy to please John.
- **Paraphrase:** \* It's eager to please John.
	- Syntactically, this is not a correct sentence.

> "the syntactical organization of an utterance is not something directly represented in any simple way in the physical structure of the utterance itself."

- The basic structures of language does not account for all the nuances of language.
	- The attachment of sentence modifiers is done completely separate to the structure of the sentence.


---


## Language Acquisition

#### Operant Conditioning
- Operant conditioning is slow and incremental.
	- Conditioning is something that increases and decreases in strength and requires multiple iterations.
- Chomsky argues that children hear scattered bits of language, and don't learn only from explicit instruction + reinforcement.
	- You create a lot of novel sentences. There is no trouble getting the structure of the sentence.

### The Poverty of the Stimulus
- We know way more than if we just stored our life experiences.
- Must be some part of language that is *innate*


#### Universal Grammar
- There's something about humans that allow us to acquire language on the basis of limited input.
	- Overcome the poverty of the stimulus and acquire language.
- We *constantly* understand and produce grammatical sentences we've never heard.
- *No form of conditioning* can explain genuinely novel, but rule-governed behavior.
	- Kids may overgeneralize a rule. "Teach" → "Teached"
	- Kids won't say sentences totally out of order.
- Knowing a language is *knowing a set of rules* for constructing well-formed sentences.
	- Learned through unknown mechanisms w/ unknown innate component.
- What is acquired when we learn to speak?
	- "Grammar"
- How do we acquire this?
	- Language seems to be something everyone can accomplish without trying to.
	- Done through observation.

### Cognitivism
- Enormously influential conception of "behavioral science" (now called cognitive science)
- Linguistic notions like meaning, reference, grammar and related psychological notions like thought, knowledge, concepts, are needed to formulate problems being studied.

## The Computational Theory of Mind
- *Not everyone endorses, but the most widely accepted.*
- Computational systems transform representations in accordance with rules.
- Representations are symbols that have *content* (ie. they *represent* things in the world; they have *intentionality*)
	- The representations are like symbols on the ticker tape for a Turing Machine.
	- We move from one thought to the next, just like a Turing Machine.
- Ex: If you think "it's raining" and "if it's raining then the streets are wet", what do you think next?
- Hypothesis: You have *symbols* in your mind that correspond to these thoughts.
	- They have the form "P" and "If P then Q"
	- **Then,** there is a rule that says to transform any pair of symbol of the form `P` and `If P then Q` into a symbol in the form of `Q`
	- This **explains and predicts** that you conclude Q, and provides a mechanism (computation)

### Reductive Neuroscience
- We can't directly *see* mental representations or computations.
- That's because presentations and computations are *functional*.
	- Just like a computer program -- **defined by what it does**
		- It's like a functional entity. E.g. Microsoft Word. (You can't find it in the computer, but what matters is that it executes the functions that it was made for.)
- But... we can directly observe and manipulate the...


- This tendency is to some extent due to practical concerns.
	- We can **observe** and **intervene** on neural processes much more easily than cognitive processes.
	- Also, that's where the money goes.
- But it often encourages a *reductive* attitude toward cognition.
	- We need to think about *why* these things in the brain are happening.
- **Cognition is nothing more** than neural mechanisms.

#### Krakauer et al.
- Cognitive Neuroscientists mounted a strong critique of reductionism.
- Their basic point: looking at neural processes alone won't tell you anything about cognition.
- You need to know what those neural processes and *implementing*.

## Reductive Neuroscience

- 

### Marr's Levels

*David Marr* famously defined three "levels" of analysis in cognitive science:

#### Computational Level

**Question:** What is the system *doing?*

- What function is it computing?
- **Examples:**
	- Flying (bird)
	- Logical inference, e.g., moving from `p` to `if p then q` to `q` (human cognition)
#### Algorithmic Level

**Question:** What is the process by which it performs function?

- What *algorithm* is it implementing? What are the symbols + processes involved?
- **Examples:**
	- Flapping wings, moving air upwards underneath (bird)
	- Symbols have logical form `P`, `if P then Q`, `Q`; built in rules take you from each logical form.

#### Implementational Level

**Question:** How is this process implemented?

- What are the *biological mechanisms*?
- **Examples:**
	- Something about feathers, muscles, etc...
	- Some collection of neural mechanisms, unknown in the case of logical #todo what?

#### Conclusion

- *Neuroscience* can not be the only way to approach studying behavior, just like how you can't just understand how birds fly by looking at their feathers.
- We have to zoom out and look at what the biology is implementing to make sense of how it works.

### Mirror Neurons

- People were very excited by this in the 90s and 00s.

> A cautionary tale

- *Speculative neuroscience* - Speculation ran wild...
	- Maybe mirror neurons show that we understand others' actions through [simulation](../../archives/cog-sci/cog-sci-finals.md#Simulation-Theory)!
	- Maybe they're *required* for understanding action!
	- Maybe *malfunctions* in mirror neurons can explain *autism*!
- ... But none of these hypotheses have robust support
	- (only thin empirical support for mirror neurons in humans, ppl w brain damage preventing motor planning still understand others' actions, etc...)

> "A potential objection to this might be to say, 'Who cares what philosphers say about the differences between psychology and neuroscience, or reductionism in general? We are scientists, not philosophers!"

- The answer to this is simple: There is *no escape* from philosophy.
- "Every scientist takes a philosophical position, either tacitly or explicitly, whenever they state that a result is..." #todo fill out

### Special Sciences

- Reductionism is a claim about "special" sciences (i.e. a science other than physics)
- Reduction of special science S to physics:
	- Take any laws of S, which says `S₁x→S₂y`
	- `S₁` is supply, `S₂` is demand (for example)
- There will be **bridge laws** that map `S₁` and `S₂`.

#### Type vs Tokens
- Type = general kind (e.g. blue)
- Token = particular instance of that token (instance of blue)

##### Token Materialism
- The view that every instance of a special science properly (like money, or psychological events) is identical to a token physical thing.
##### Type Materialism
- The view that every general kind of a special science property is identical to a type of physical thing.

### Special Sciences
- **Fodor's claim:** There are no actual laws of physics that involve these weird disjunctive predicates. (*Disjunctive kinds are arbitrary*)
	- Ex: There's no laws that say Either this or this increases will lead to this or this increasing, etc...
- How would you put Fodor's point, using the example of a law of economics (e.g. printing excess money causes inflation?)
## LoT vs Connectionism
- Fodor & Pylyshyn are interested in [mental architecture](../../archives/cog-decision/cognitive-architecture.md)
	- They argue there must be a *language of thought (LoT)*
	- In other words, mental representations must have a language-like structure.
- Mental architecture = the most basic building blocks of psychology.
- What are the primitive units of thought? And how do we derive all the complexity of human behavior from those units?
- **Most important Qs at the heart of CogSci**

### Combinatorial Syntax & Semantics
- Fundamental difference between *simple* ("atomic") and *complex* ("molecular") representations.
- Complexed representations contain simple representations.

---

English sentence: "**John loves Mary**"

- This expresses the proposition that *John loves Mary*
- It also has a part corresponds to *John*, a part that corresponds to *Mary*, and a part that corresponds to the *loving relation*.
- Language-like representations have **constituents (parts)** and a *syntactic* relation between them.

---

- Fodor and Pylyshyn's claim: thoughts have this same sort of structure.
- Thoughts have *constituents*, and a *syntactic relation* between them.
- This is the **LoT Hypothesis**

### Structure-Sensitive Operations
- If thoughts have a combinatorial syntax & semantics, you can compute over types of structure.
	- P&Q transformed into P
	- P→Q and P transformed into Q
- So... If there is a classical, LoT architecture in the mind, then we should find lots of computations that are sensitive to structure.
	- There should be a logic of thought
- *Not necessarily the same logic that you learn in logic classes.*

### Connectionism

> Check out old notes from [Cog Sci](../../archives/cog-sci/4-artificial-minds.md#Evaluating-Connectionism).

- The Alternative to LoT. (Looks like neural networks)
- Representations are nodes 
- Very useful in semantic priming.
	- If you've read the word 'doctor' you'll be better at discriminating 'nurse' than 'bread'
- Common explanation to semantic priming is that there is a "semantic network" in memory.
	- Spreading activation through the network.
- Representations that mean *doctor* and *nurse* are linked; so are *bread* and *butter*; but *doctor* and *bread* are not.

## Language of Thought
- Fodor & Pylyshyn argued that thought has to have a language-like structure
	- Compositional syntax & and semantics.
		- Put simple structures together to make more complexed structures.
	- Structure sensitive operations.
		- Being able to go, x is F, if x is F, then x is G, and go to x is G.
		- Whatever the variables mean, you can still get to x is G
		- Allows you to do logical thinking.
		- Perform the operations on these more complexed structures.

> **Breakdown:** here are the different structures, and here are the more complexed operations you can run on these structures.


### Two options

1. We think in our spoken, *natural* language -- thinking = reusing language in your head, & people who speak different languages will have a different LoT.
2. There is innate LoT, independent of natural language -- the classic LoT hypothesis


##### LoT Cont
- Fodor strongly preferred option 2
- One argument: How do we learn natural language in the first place?
- Seems like we learn the word "dog" by learning that "dog" means *dog*.
- You have to already have the concept DOG to learn that "dog" refers to dogs.

---

- But there are some other empirical ways into this problem.
- For example: What about people who lose their ability to use natural language?
- This condition is called *aphasia*.
- If we think in natural  language, aphasics should show massive cognitive deficits.
- If we think in an innate LoT, then in principle there should be aphasics w minimal cognitive deficits.

---

- Two components of natural language -> Lexicon and Grammar.
- **Lexicon:** Representations of primitive meaningful units of the language.
	- "walk"/"dog"/"-ing"
- **Grammar:** System of rules used to derive complex expressions from simple ones.
	- "dog walking"; "walking the dog"; "The dog is walking"


One might think one or both aspects of language are responsible for human-like cognition.

### Lexicon & Thought
- Novelty-preference task: kids look longer + reach for *new* items.
- 13 m/o are shown some objects, including a car.
- Either given a word ("This is a car") or not
- Then they see two objects: an airplane, and a *different* car.
- Word condition: preference for airplane.
	- The word is queue them to categorize the object as a car.
	- If given a car and prompted with the word car, they would prefer the more novel airplane.
- Even works with new words (made up like: *This is a dax!*)

---

- Suggests that words are "invitations to form categories" (i.e. concepts)
- Varley cites evidence that chimps who learn the words 'same' and 'different' are better at same/different tasks (premack 1988)
- Suggests lexicon might be a crucial aid to cognition.

### Grammar & Thought
- Another idea is that **grammar** play a key role.
- Chimps and other animals have a limited ability to *combine* symbols.
- Perhaps this is the cause of their lack of humanlike cognition.


----

> The ability to concatenate and embed linguistic expressions might allow for increasingly complex forms of thought. For example, long chains of inferences in conditional or causal reasoning might become possible with the availability of sentential forms and their various connectors."

- This ability to take expressions and make them more and more complexed.

> Sally thinks that the marble is in the basket. (Theory of mind)

### Aphasia
- Two forms of aphasia.
- **Agrammatism**: lack of ability to use grammar
	- The boy kissed the girl/The girl kissed the boy
	- Unable to tell the difference between these two words.
		- Lose ability to put the different components of the sentence together.
- **Anomia**: Lack of ability to use lexicon.
	- Use of individual words.
- Not entirely distinct (impairments of one always correlate to some impairment of the other, but not equally severe.)

#### Anomia
- Evidence of impairment: Lupyan & Mirman (2013)
	- SS included anomic aphasics & healthy controls
	- Task: Categorize objects
- When categorizing things with many features in common (e.g. fruits), no impairment.
	- When a lot of defining features of a category, no impairment.
- When categorizing things that have only a few features in common (e.g. things made of wood), aphasics were impaired.

> Varley: But they didn't include a group w cognitive deficits but no language deficit to compare; just healthy controls.

- You don't know that you isolated the specific linguistic computation as the causal reasoning for the aphasia.

#### Agrammatism
- Does verbal shadowing (saying words out loud that you're hearing) disrupt task performance?
	- Does it disrupt compositional thought??
- Example:  [Theory of mind](../../archives/cog-sci/11-emergence-of-the-mind.md#Theory-Of-Mind) (working out other people's beliefs)
- **False belief task**
	- Sally Ann hides a doll in a drawer, then leaves the room
	- Somebody comes in and moves the doll to a different drawer
	- Task: which drawer will Sally Ann look in? First one, b.c. she falsely believes that's where the doll is)

##### Example: Agrammatism
- Subject SA had sever agrammatism.
- Nonetheless capable of distinguishing what's really in a container (eg. a book containing hidden necklace) from what somebody *think* was in the container? (...the pages)
- *There is also a debate about whether infants and animals have theory of mind.*
	- Kids don't pass the false belief task till ~ age 3.5
	- But looking time shows 15 m/os that lack cognitive vocab will look longer when people act contrary to their false beliefs. (e.g. Sally thinks the doll is in the first drawer but looks in the second drawer)
		- Even though kids can't use the judgment, they are still implicitly representing it in their mind.
	- *Replication issues*

**ToM** tasks require embedding mental representations in a *compositional* way.

- Taking one representation and making it into a *constituent* of another.
- Representing someone else's mental state and simulating their representations.

		The doll is in the drawer. (Ann moves it) <- Learning this is false does NOT make children think the second statement is false.
		Sally thinks [the doll is in the drawer]

- Presence in agrammatic aphasics suggests that LoT is independent of natural language.

#### Calculation
- With math, `7-5=?` vs `5-7=?`
- People with agrammatism was nonetheless good at calculation.
	- Even though this feels like a structure-sensitive operation....

---

- This suggests that the ability to compose representations in complex ways is **not** dependent on grammar of natural language.

---

#### Cross-Domain Integration
- One purpose language might have is facilitating information across different cognitive systems.
	- Can you give an example?
- Task: You have to walk to a corner in the room, but after you see the room, you're spun around and disoriented.
	- If there's a landmark (e.g. an odor or an object), Ss can find their way to it by integrating it with mental map of where the target corner is.
- Verbal shadowing negatively affects performance.
- *Children* who can't use 'left' or 'right' terms fail at this task....
- However, severe aphasics performed well on this task...
	- *Even* when doing the limited verbal shadowing that they're capable of!

### Language -> Thought?

Aphasics are capable of complexed, compositional thought:

- ToM
- Calculation
- Cross-domain integration
- Suggests that complexed thought is functionally *dissociable* from language.
	- There's some kind of disassociability.
- Good news for the language of thought hypothesis.

---

- So, what role does language play in cognition then?
- We can use language in our heads ("inner speech")
- It may have some useful functions - e.g. cues to form categories, helping keep something in memory.

#### Example
- If you have to keep a string of numbers memorized for a minute, what strategy might you use?
- You might sing it in your head as a melody...

# Connectionism


## Research Programs
- A simple approach to philosophy of science: we have hypotheses that are true or false, and we confirm them with empirical tests.
- But to know whether a piece of evidence should be interpreted as *confirming* your hypothesis, you have to have a whole theory with tons of "auxiliary assumptions"
- Other philosophers argued that *falsification* is the key to **substantive** scientific claims.
- However, Lakatos argued that *research programs* that are not fruitful or not play a bigger role in science than hypotheses/theories that are true or not.


---

- For Lakatos, research programs consist of a "core" and a "belt"
- Core: background assumptions about what you're studying:
	- Not typically challenged from within the research program.
- Belt: Auxiliary hypothesis that are directly empirically tested.
	- Can be challenged/changed frequently without threating the core of the research program.

> These research programs *thrive* or *die* based on if they are *progressive* or *degenerating*.


- **Progressive research programs:** generate new findings, new auxiliary (belt) hypotheses.
- **Degenerating research programs:** No new predictions to test, no new hypotheses.

> *Lakatos:* Degeneration of a research program is the real reason why ideas die out in science, not outright falsification (Behaviorism)

### Neuroconnectionism

- The **Core:**
	- Artificial Neural Networks (ANN) are in the "Goldilocks zone" of computational abstraction for *capturing neural computations* - not too detailed, not too abstract.
- The **Belt:**
	- A series of particular hypotheses and experimental results about the similarities and differences between various ANNs and brain activity.
- **Example:** Using neural networks to model the visual system.
	- Architectures, data sets, objectives, and learning rules have all been tinkered with to improve model/brain similarity.
- **Four central ingredients of ANNs:**
	- Architectures, data sets, objectives and learning rules

### ANN

#### Ingredients

##### Architectures
- Basic computational scaffold.

##### Data Sets
- Large databases, usually image or text.

##### Objectives
- Goals like classification, efficiency.

##### Learning Rules
- Rules used for changing weights to reduce error.

---



#### Neurosymbolic Approach

- "Neurosymbolic" approaches hard code LoT-style symbols alongside ANNs into one integrated, hybrid model.
- The symbols are useful for representing novel combinations of concepts, representing abstract rules, and storing discrete facts.
- The ANN components are useful for learning from large amounts of data.